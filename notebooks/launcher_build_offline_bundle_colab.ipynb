{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e4fd2c",
   "metadata": {},
   "source": [
    "# Offline Bundle Builder Launcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10a244",
   "metadata": {},
   "source": [
    "\n",
    "## Purpose of this notebook\n",
    "\n",
    "This notebook is a script-first, notebook-as-launcher interface for building the offline ontology bundle used by the inference pipeline.\n",
    "\n",
    "This notebook:\n",
    "- sets up a clean execution environment (Colab),\n",
    "- clones the repository,\n",
    "- installs dependencies,\n",
    "- acquires the ontology (from URL or local upload),\n",
    "- launches the official CLI script build_ontology_bundle.py,\n",
    "- collects logs and outputs in a reproducible way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a7023",
   "metadata": {},
   "source": [
    "## What is produced by this notebook\n",
    "\n",
    "Running this notebook produces:\n",
    "- an internal ontology CSV (iri, label, text, …),\n",
    "- an offline bundle (offline_bundle.pkl) containing:\n",
    "   - exact match structures,\n",
    "   - lexical retrieval structures,\n",
    "   - semantic index,\n",
    "   - execution logs and command trace.\n",
    "\n",
    "All outputs are saved in a single run directory and can be downloaded as a ZIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a063d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c025fe0e",
   "metadata": {},
   "source": [
    "### Runtime check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca9b30",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi -L || echo \"No GPU detected (CPU runtime)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ea9d1",
   "metadata": {},
   "source": [
    "Building the semantic index is computationally expensive. GPU runtime is strongly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1b59b",
   "metadata": {},
   "source": [
    "### Clone repository (reproducible setup)\n",
    "This notebook only runs the official scripts from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a93fe2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "REPO_URL=\"https://github.com/adsp-polito/2025-P13-Ontology-Alignment.git\"\n",
    "REPO_DIR=\"2025-P13-Ontology-Alignment\"\n",
    "\n",
    "# Optional: lock to a specific commit for full reproducibility\n",
    "COMMIT=\"\"   # e.g. \"4ffd790\"\n",
    "\n",
    "rm -rf \"$REPO_DIR\"\n",
    "git clone \"$REPO_URL\" \"$REPO_DIR\"\n",
    "cd \"$REPO_DIR\"\n",
    "\n",
    "if [ -n \"$COMMIT\" ]; then\n",
    "  git checkout \"$COMMIT\"\n",
    "fi\n",
    "\n",
    "echo \"Checked out commit:\"\n",
    "git rev-parse HEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109fc90",
   "metadata": {},
   "source": [
    "### Enter the repo directory\n",
    "\n",
    "Colab runs each bash cell in its own subshell.\n",
    "To keep the notebook state consistent, we move into the cloned repository using %cd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c773241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 2025-P13-Ontology-Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314bd45",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe75e8a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "python -m pip install --upgrade pip\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bca78",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c645b8",
   "metadata": {},
   "source": [
    "### Ontology input: choose ONE option\n",
    "The ontology can be provided either as:\n",
    "- a remote URL, or\n",
    "- a local file upload.\n",
    "\n",
    "Only one option is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13bd99",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "mkdir -p outputs\n",
    "ENV_FILE=\"outputs/oa_env.sh\"\n",
    ": > \"$ENV_FILE\"\n",
    "echo \"[INFO] Env file reset at $ENV_FILE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a11208",
   "metadata": {},
   "source": [
    "#### Option A — Ontology from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005725de",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "ENV_FILE=\"outputs/oa_env.sh\"\n",
    "mkdir -p \"$(dirname \"$ENV_FILE\")\"\n",
    "\n",
    "# --- Choose ONE of the two ---\n",
    "# Option A: download from URL (set a real URL)\n",
    "ONTO_URL=\"\"   # e.g. \"https://raw.githubusercontent.com/.../envo.owl\"\n",
    "\n",
    "# Option B: local file already present (path inside Colab/VM)\n",
    "ONTO_LOCAL_PATH=\"/content/2025-P13-Ontology-Alignment/datasets/envo.owl\"\n",
    "\n",
    "# --- Logic ---\n",
    "if [ -n \"${ONTO_URL}\" ]; then\n",
    "  echo \"[INFO] Downloading ontology from URL...\"\n",
    "  mkdir -p \"$(dirname \"$ONTO_LOCAL_PATH\")\"\n",
    "  wget -q --show-progress -O \"$ONTO_LOCAL_PATH\" \"$ONTO_URL\"\n",
    "else\n",
    "  echo \"[INFO] ONTO_URL empty -> using local file.\"\n",
    "fi\n",
    "\n",
    "# --- Sanity checks ---\n",
    "if [ ! -f \"$ONTO_LOCAL_PATH\" ]; then\n",
    "  echo \"[ERROR] Ontology file not found at: $ONTO_LOCAL_PATH\"\n",
    "  echo \"        Either set ONTO_URL to a valid URL OR set ONTO_LOCAL_PATH to an existing file.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "ls -lh \"$ONTO_LOCAL_PATH\"\n",
    "\n",
    "# Save to env file (overwrite the variable line cleanly)\n",
    "# (avoid duplicating exports every run)\n",
    "grep -v '^export ONTO_LOCAL_PATH=' \"$ENV_FILE\" 2>/dev/null > \"${ENV_FILE}.tmp\" || true\n",
    "mv \"${ENV_FILE}.tmp\" \"$ENV_FILE\"\n",
    "echo \"export ONTO_LOCAL_PATH=\\\"$ONTO_LOCAL_PATH\\\"\" >> \"$ENV_FILE\"\n",
    "\n",
    "echo \"[INFO] Saved ONTO_LOCAL_PATH to $ENV_FILE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c1bea",
   "metadata": {},
   "source": [
    "#### Option B — Upload ontology file manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55241d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os, pathlib\n",
    "\n",
    "ENV_FILE=\"outputs/oa_env.sh\"\n",
    "uploaded = files.upload()\n",
    "fname = next(iter(uploaded.keys()))\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "onto_path = f\"data/{fname}\"\n",
    "with open(onto_path, \"wb\") as f:\n",
    "    f.write(uploaded[fname])\n",
    "\n",
    "with open(ENV_FILE, \"a\") as f:\n",
    "    f.write(f'export ONTO_LOCAL_PATH=\"{onto_path}\"\\n')\n",
    "\n",
    "print(\"Saved:\", onto_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75178523",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "The following cell verifies that the ontology path has been correctly set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d8a92",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "ENV_FILE=\"outputs/oa_env.sh\"\n",
    "test -f \"$ENV_FILE\"\n",
    "source \"$ENV_FILE\"\n",
    "\n",
    "test -n \"${ONTO_LOCAL_PATH:-}\"\n",
    "test -f \"$ONTO_LOCAL_PATH\"\n",
    "ls -lh \"$ONTO_LOCAL_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0c223",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7c9d1",
   "metadata": {},
   "source": [
    "### Configure output directory\n",
    "Each execution produces a self-contained run folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b67b9a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "ENV_FILE=\"outputs/oa_env.sh\"\n",
    "\n",
    "RUN_ID=\"offline_bundle_run_$(date +%Y%m%d_%H%M%S)\"\n",
    "OUT_DIR=\"outputs/${RUN_ID}\"\n",
    "mkdir -p \"$OUT_DIR\"\n",
    "\n",
    "OUT_CSV=\"${OUT_DIR}/internal_ontology.csv\"\n",
    "OUT_BUNDLE=\"${OUT_DIR}/offline_bundle.pkl\"\n",
    "OUT_LOG=\"${OUT_DIR}/build_bundle.log\"\n",
    "\n",
    "echo \"export OUT_DIR=\\\"$OUT_DIR\\\"\"       >> \"$ENV_FILE\"\n",
    "echo \"export OUT_CSV=\\\"$OUT_CSV\\\"\"       >> \"$ENV_FILE\"\n",
    "echo \"export OUT_BUNDLE=\\\"$OUT_BUNDLE\\\"\" >> \"$ENV_FILE\"\n",
    "echo \"export OUT_LOG=\\\"$OUT_LOG\\\"\"       >> \"$ENV_FILE\"\n",
    "\n",
    "echo \"$OUT_DIR\" > outputs/LAST_RUN_DIR.txt\n",
    "echo \"[INFO] OUT_DIR=$OUT_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538f3e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028afb2",
   "metadata": {},
   "source": [
    "### Configure model and preprocessing parameters\n",
    "These parameters are passed directly to the CLI script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59538626",
   "metadata": {},
   "source": [
    "- `TOKENIZER_NAME` must match the tokenizer used by the cross-encoder at inference time.\n",
    "- `BI_ENCODER_MODEL_ID` is used ONLY to build the semantic index (offline).\n",
    "- These choices do NOT affect training here, only retrieval quality at inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350c9d3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "ENV_FILE=\"outputs/oa_env.sh\"\n",
    "\n",
    "TOKENIZER_NAME=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "BI_ENCODER_MODEL_ID=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "\n",
    "SEMANTIC_BATCH_SIZE=64\n",
    "SEMANTIC_MAX_LENGTH=256\n",
    "NO_SEMANTIC_NORMALIZE=0\n",
    "\n",
    "PREFIX=\"http://purl.obolibrary.org/obo/ENVO_\"\n",
    "\n",
    "echo \"export TOKENIZER_NAME=\\\"$TOKENIZER_NAME\\\"\"           >> \"$ENV_FILE\"\n",
    "echo \"export BI_ENCODER_MODEL_ID=\\\"$BI_ENCODER_MODEL_ID\\\"\" >> \"$ENV_FILE\"\n",
    "echo \"export SEMANTIC_BATCH_SIZE=\\\"$SEMANTIC_BATCH_SIZE\\\"\" >> \"$ENV_FILE\"\n",
    "echo \"export SEMANTIC_MAX_LENGTH=\\\"$SEMANTIC_MAX_LENGTH\\\"\" >> \"$ENV_FILE\"\n",
    "echo \"export NO_SEMANTIC_NORMALIZE=\\\"$NO_SEMANTIC_NORMALIZE\\\"\" >> \"$ENV_FILE\"\n",
    "echo \"export PREFIX=\\\"$PREFIX\\\"\"                           >> \"$ENV_FILE\"\n",
    "\n",
    "echo \"[INFO] Model config saved.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87db690",
   "metadata": {},
   "source": [
    "### Practical Notes\n",
    "If the ontology is too big and the semantic index is heavy:\n",
    "- reduce --semantic-batch-size (es. 16/32)\n",
    "- reduce --semantic-max-length (es. 128/192) if “RICH_TEXT” is big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cd3ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc868b6",
   "metadata": {},
   "source": [
    "## Launch offline bundle construction\n",
    "This is the only cell that performs real computation. Everything is logged and fully reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f95fc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "source outputs/oa_env.sh\n",
    "\n",
    "mkdir -p \"$OUT_DIR\"\n",
    "\n",
    "CMD=\"python build_ontology_bundle.py \\\n",
    "  --ont-path \\\"$ONTO_LOCAL_PATH\\\" \\\n",
    "  --out-csv \\\"$OUT_CSV\\\" \\\n",
    "  --out-bundle \\\"$OUT_BUNDLE\\\" \\\n",
    "  --tokenizer-name \\\"$TOKENIZER_NAME\\\" \\\n",
    "  --bi-encoder-model-id \\\"$BI_ENCODER_MODEL_ID\\\" \\\n",
    "  --semantic-batch-size \\\"$SEMANTIC_BATCH_SIZE\\\" \\\n",
    "  --semantic-max-length \\\"$SEMANTIC_MAX_LENGTH\\\"\"\n",
    "\n",
    "if [ -n \"${PREFIX:-}\" ]; then\n",
    "  CMD=\"$CMD --prefix \\\"$PREFIX\\\"\"\n",
    "fi\n",
    "\n",
    "if [ \"${NO_SEMANTIC_NORMALIZE:-0}\" = \"1\" ]; then\n",
    "  CMD=\"$CMD --no-semantic-normalize\"\n",
    "fi\n",
    "\n",
    "echo \"$CMD\" | tee \"$OUT_DIR/command.txt\"\n",
    "bash -lc \"$CMD\" 2>&1 | tee \"$OUT_LOG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa245ce3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745f00f",
   "metadata": {},
   "source": [
    "### Sanity check (no inference)\n",
    "This cell does not score anything.\n",
    "It only verifies that the bundle loads correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ontologies.offline_preprocessing import load_offline_bundle\n",
    "\n",
    "out_dir = Path(open(\"outputs/LAST_RUN_DIR.txt\").read().strip())\n",
    "bundle_path = out_dir / \"offline_bundle.pkl\"\n",
    "\n",
    "bundle = load_offline_bundle(bundle_path, load_semantic_embeddings_=True, mmap=True)\n",
    "print(\"Bundle keys:\", list(bundle.keys()))\n",
    "sem = bundle.get(\"semantic_index\", {})\n",
    "print(\"Semantic keys:\", list(sem.keys()))\n",
    "print(\"Embeddings shape:\", getattr(sem.get(\"embeddings\", None), \"shape\", None))\n",
    "print(\"#IRIs:\", len(sem.get(\"iris\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9427a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789893d8",
   "metadata": {},
   "source": [
    "## Package outputs for download\n",
    "Package the outputs of the current run into a single archive that can be downloaded and reused locally or in downstream pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af308822",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUT_DIR=$(cat outputs/LAST_RUN_DIR.txt)\n",
    "ZIP_PATH=\"${OUT_DIR}.zip\"\n",
    "\n",
    "zip -r \"$ZIP_PATH\" \"$OUT_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2355b14",
   "metadata": {},
   "source": [
    "Download the generated archive from the Colab environment to the local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9037ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "with open(\"outputs/LAST_RUN_DIR.txt\") as f:\n",
    "    OUT_DIR = f.read().strip()\n",
    "\n",
    "files.download(f\"{OUT_DIR}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OAvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
