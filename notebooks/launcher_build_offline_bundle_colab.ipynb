{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e4fd2c",
   "metadata": {},
   "source": [
    "# Offline Bundle Builder Launcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10a244",
   "metadata": {},
   "source": [
    "\n",
    "## Purpose of this notebook\n",
    "\n",
    "This notebook is a script-first, notebook-as-launcher interface for building the offline ontology bundle used by the inference pipeline.\n",
    "\n",
    "This notebook:\n",
    "- sets up a clean execution environment (Colab),\n",
    "- clones the repository,\n",
    "- installs dependencies,\n",
    "- acquires the ontology (from URL or local upload),\n",
    "- launches the official CLI script build_ontology_bundle.py,\n",
    "- collects logs and outputs in a reproducible way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a7023",
   "metadata": {},
   "source": [
    "## What is produced by this notebook\n",
    "\n",
    "Running this notebook produces:\n",
    "- an internal ontology CSV (iri, label, text, …),\n",
    "- an offline bundle (offline_bundle.pkl) containing:\n",
    "   - exact match structures,\n",
    "   - lexical retrieval structures,\n",
    "   - semantic index,\n",
    "   - execution logs and command trace.\n",
    "\n",
    "All outputs are saved in a single run directory and can be downloaded as a ZIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a063d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c025fe0e",
   "metadata": {},
   "source": [
    "### Runtime check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca9b30",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi -L || echo \"No GPU detected (CPU runtime)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ea9d1",
   "metadata": {},
   "source": [
    "Building the semantic index is computationally expensive. GPU runtime is strongly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1b59b",
   "metadata": {},
   "source": [
    "### Clone repository (reproducible setup)\n",
    "This notebook only runs the official scripts from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a93fe2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "REPO_URL=\"https://github.com/adsp-polito/2025-P13-Ontology-Alignment.git\"\n",
    "REPO_DIR=\"2025-P13-Ontology-Alignment\"\n",
    "\n",
    "# Optional: lock to a specific commit for full reproducibility\n",
    "COMMIT=\"\"   # e.g. \"4ffd790\"\n",
    "\n",
    "rm -rf \"$REPO_DIR\"\n",
    "git clone \"$REPO_URL\" \"$REPO_DIR\"\n",
    "cd \"$REPO_DIR\"\n",
    "\n",
    "if [ -n \"$COMMIT\" ]; then\n",
    "  git checkout \"$COMMIT\"\n",
    "fi\n",
    "\n",
    "git rev-parse HEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109fc90",
   "metadata": {},
   "source": [
    "### Enter the repo directory\n",
    "\n",
    "Colab runs each bash cell in its own subshell.\n",
    "To keep the notebook state consistent, we move into the cloned repository using %cd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c773241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 2025-P13-Ontology-Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314bd45",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe75e8a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip -q install --upgrade pip\n",
    "pip -q install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bca78",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c645b8",
   "metadata": {},
   "source": [
    "### Ontology input: choose ONE option\n",
    "The ontology can be provided either as:\n",
    "- a remote URL, or\n",
    "- a local file upload.\n",
    "\n",
    "Only one option is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a11208",
   "metadata": {},
   "source": [
    "#### Option A — Ontology from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005725de",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ONTO_URL=\"https://example.com/your_ontology.owl\"   # ← change this\n",
    "ONTO_LOCAL_PATH=\"data/input_ontology.owl\"\n",
    "\n",
    "mkdir -p data\n",
    "wget -O \"$ONTO_LOCAL_PATH\" \"$ONTO_URL\"\n",
    "ls -lh \"$ONTO_LOCAL_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c1bea",
   "metadata": {},
   "source": [
    "#### Option B — Upload ontology file manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55241d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "uploaded = files.upload()\n",
    "fname = next(iter(uploaded.keys()))\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "ONTO_LOCAL_PATH = f\"data/{fname}\"\n",
    "\n",
    "with open(ONTO_LOCAL_PATH, \"wb\") as f:\n",
    "    f.write(uploaded[fname])\n",
    "\n",
    "print(\"Ontology saved to:\", ONTO_LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0c223",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7c9d1",
   "metadata": {},
   "source": [
    "### Configure output directory\n",
    "Each execution produces a self-contained run folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b67b9a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "RUN_ID=\"offline_bundle_run_$(date +%Y%m%d_%H%M%S)\"\n",
    "OUT_DIR=\"outputs/${RUN_ID}\"\n",
    "\n",
    "mkdir -p \"$OUT_DIR\"\n",
    "echo \"$OUT_DIR\" > outputs/LAST_RUN_DIR.txt\n",
    "\n",
    "OUT_CSV=\"${OUT_DIR}/internal_ontology.csv\"\n",
    "OUT_BUNDLE=\"${OUT_DIR}/offline_bundle.pkl\"\n",
    "OUT_LOG=\"${OUT_DIR}/build_bundle.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538f3e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028afb2",
   "metadata": {},
   "source": [
    "### Configure model and preprocessing parameters\n",
    "These parameters are passed directly to the CLI script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_NAME=\"dmis-lab/biobert-base-cased-v1.1\"\n",
    "\n",
    "# Bi-encoder used to build the semantic index\n",
    "BI_ENCODER_MODEL_ID=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "SEMANTIC_BATCH_SIZE=64\n",
    "SEMANTIC_MAX_LENGTH=256\n",
    "\n",
    "NO_SEMANTIC_NORMALIZE = 0  # Set to 1 to disable normalization of semantic embeddings\n",
    "\n",
    "# Optional: restrict ontology classes by IRI prefix\n",
    "PREFIX=\"\"   # e.g. \"http://purl.obolibrary.org/obo/ENVO_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87db690",
   "metadata": {},
   "source": [
    "### Practical Notes\n",
    "If the ontology is too big and the semantic index is heavy:\n",
    "- reduce --semantic-batch-size (es. 16/32)\n",
    "- reduce --semantic-max-length (es. 128/192) if “RICH_TEXT” is big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cd3ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc868b6",
   "metadata": {},
   "source": [
    "## Launch offline bundle construction\n",
    "This is the only cell that performs real computation. Everything is logged and fully reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f95fc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CMD=\"python build_ontology_bundle.py \\\n",
    "  --ont-path ${ONTO_LOCAL_PATH} \\\n",
    "  --out-csv ${OUT_CSV} \\\n",
    "  --out-bundle ${OUT_BUNDLE} \\\n",
    "  --tokenizer-name ${TOKENIZER_NAME} \\\n",
    "  --bi-encoder-model-id ${BI_ENCODER_MODEL_ID} \\\n",
    "  --semantic-batch-size ${SEMANTIC_BATCH_SIZE} \\\n",
    "  --semantic-max-length ${SEMANTIC_MAX_LENGTH} \\\n",
    "  --no-semantic-normalize ${NO_SEMANTIC_NORMALIZE} \\\n",
    "\"\n",
    "\n",
    "\n",
    "if [ -n \\\"$PREFIX\\\" ]; then\n",
    "  CMD=\\\"$CMD --prefix ${PREFIX}\\\"\n",
    "fi\n",
    "\n",
    "echo \"$CMD\" | tee \"${OUT_DIR}/command.txt\"\n",
    "bash -lc \"$CMD\" 2>&1 | tee \"$OUT_LOG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa245ce3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745f00f",
   "metadata": {},
   "source": [
    "### Sanity check (no inference)\n",
    "This cell does not score anything.\n",
    "It only verifies that the bundle loads correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontologies.offline_preprocessing import load_offline_bundle\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"outputs/LAST_RUN_DIR.txt\") as f:\n",
    "    OUT_DIR = f.read().strip()\n",
    "\n",
    "OUT_BUNDLE = Path(OUT_DIR) / \"offline_bundle.pkl\"\n",
    "\n",
    "bundle = load_offline_bundle(\n",
    "    OUT_BUNDLE,\n",
    "    load_semantic_embeddings=True,\n",
    "    mmap=True,\n",
    ")\n",
    "\n",
    "print(\"Bundle keys:\", list(bundle.keys()))\n",
    "\n",
    "if \"semantic_index\" in bundle:\n",
    "    sem = bundle[\"semantic_index\"]\n",
    "    print(\"Semantic index fields:\", list(sem.keys()))\n",
    "    print(\"Number of classes:\", len(sem.get(\"iris\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9427a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789893d8",
   "metadata": {},
   "source": [
    "## Package outputs for download\n",
    "Package the outputs of the current run into a single archive that can be downloaded and reused locally or in downstream pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af308822",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUT_DIR=$(cat outputs/LAST_RUN_DIR.txt)\n",
    "ZIP_PATH=\"${OUT_DIR}.zip\"\n",
    "\n",
    "zip -r \"$ZIP_PATH\" \"$OUT_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2355b14",
   "metadata": {},
   "source": [
    "Download the generated archive from the Colab environment to the local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9037ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "with open(\"outputs/LAST_RUN_DIR.txt\") as f:\n",
    "    OUT_DIR = f.read().strip()\n",
    "\n",
    "files.download(f\"{OUT_DIR}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OAvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
