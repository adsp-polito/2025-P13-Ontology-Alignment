{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53d98fe",
   "metadata": {},
   "source": [
    "# Ontology Alignment — Full Pipeline (Local Notebook)\n",
    "\n",
    "This notebook runs the **entire pipeline locally**:\n",
    "\n",
    "1. **Dataset construction** (build source/target CSV + build training dataset + splits)\n",
    "2. **Training** (cross-encoder fine-tuning)\n",
    "3. **Offline bundle building** (ontology_internal.csv + offline_bundle.pkl, with optional semantic index)\n",
    "4. **Inference** (retrieval + cross-encoder scoring → predictions.csv)\n",
    "\n",
    "It is designed to be:\n",
    "- **reproducible**: every run writes to `outputs/<RUN_ID>/...`\n",
    "- **modular**: you can run only the stages you need via flags\n",
    "- **terminal-free**: commands are launched via notebook cells and logged to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d101a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e2014",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "Run this section once per environment.\n",
    "\n",
    "Two typical workflows:\n",
    "\n",
    "- **You are already inside the repo**  \n",
    "  Just install dependencies (once) and continue.\n",
    "\n",
    "- **You want the notebook to clone the repo**  \n",
    "  Clone, `cd` into it, install dependencies.\n",
    "\n",
    "Notes:\n",
    "- In Jupyter, `!pip install ...` installs into the kernel environment.\n",
    "- Make sure the notebook kernel is the same env you intend to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTIONAL: clone repo ---\n",
    "# !git clone https://github.com/adsp-polito/2025-P13-Ontology-Alignment.git\n",
    "# %cd 2025-P13-Ontology-Alignment\n",
    "\n",
    "# --- OPTIONAL: install deps ---\n",
    "# If you have requirements.txt:\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "# Fallback minimal (only if needed):\n",
    "# !pip install -U sentence-transformers transformers torch pandas numpy scikit-learn\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011b51c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0916a",
   "metadata": {},
   "source": [
    "## 1) Helpers (run_cmd + logs) + robust W&B disable\n",
    "\n",
    "We run the pipeline scripts (`training.py`, `build_ontology_bundle.py`, `run_inference.py`) as subprocesses.\n",
    "Each command writes a log file. If the command fails, the notebook prints the tail of the log.\n",
    "\n",
    "Important:\n",
    "- Some training stacks try to use Weights & Biases (wandb).  \n",
    "  In local setups this can fail (missing API key).  \n",
    "  We force-disable wandb inside subprocess environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc04bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def print_tail(path: Path, n=120):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"[tail] log not found: {p}\")\n",
    "        return\n",
    "    lines = p.read_text(errors=\"replace\").splitlines()\n",
    "    print(\"\\n\".join(lines[-n:]))\n",
    "\n",
    "def run_cmd(cmd, log_path: Path, cwd: Path):\n",
    "    cmd = [str(x) for x in cmd]\n",
    "    log_path = Path(log_path)\n",
    "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"\\nRunning command:\\n\", \" \".join(cmd))\n",
    "    print(\"CWD:\", Path(cwd).resolve())\n",
    "    print(\"Log:\", log_path.resolve())\n",
    "\n",
    "    # --- Robust: disable W&B for subprocess ---\n",
    "    # Use WANDB_MODE=disabled (safe).\n",
    "    # Avoid WANDB_DISABLED because some stacks conflict when report_to='wandb' is explicitly set.\n",
    "    env = os.environ.copy()\n",
    "    env[\"WANDB_MODE\"] = \"disabled\"\n",
    "    env[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "    with open(log_path, \"w\") as f:\n",
    "        proc = subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            cwd=str(cwd),\n",
    "            env=env,\n",
    "        )\n",
    "\n",
    "    print(\"Return code:\", proc.returncode)\n",
    "    if proc.returncode != 0:\n",
    "        print(\"!!! Error occurred. Last lines of log:\")\n",
    "        print_tail(log_path, n=120)\n",
    "        raise RuntimeError(f\"Command failed with return code {proc.returncode}. See log: {log_path}\")\n",
    "    return proc.returncode\n",
    "\n",
    "print(\"Helpers OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d111bb4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043265c8",
   "metadata": {},
   "source": [
    "## 2) Run mode flags (choose what to run today)\n",
    "\n",
    "This notebook supports two styles:\n",
    "\n",
    "- **Full pipeline**: Training → Offline → Inference (one run)\n",
    "- **Stage-by-stage**: run only the stages you need\n",
    "\n",
    "You can also “restore” artifacts (point to existing files) and skip rebuilding.\n",
    "\n",
    "Key dependencies:\n",
    "- Inference requires offline artifacts (bundle + ontology CSV).\n",
    "- Inference requires a cross-encoder model id/path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# RUN MODE FLAGS (choose what to run today)\n",
    "# ============================================\n",
    "\n",
    "# Main toggles: what stages to execute\n",
    "DO_TRAINING  = True\n",
    "DO_OFFLINE   = True\n",
    "DO_INFERENCE = True\n",
    "\n",
    "# Restore toggles: if True, skip building that stage and load artifacts instead\n",
    "RESTORE_MODEL   = False   # restores cross-encoder (+ optionally custom inference input CSV/schema)\n",
    "RESTORE_OFFLINE = False   # restores offline bundle + ontology CSV\n",
    "\n",
    "# Coherence hints (not hard errors)\n",
    "if DO_TRAINING and RESTORE_MODEL:\n",
    "    print(\"Note: DO_TRAINING=True but RESTORE_MODEL=True. Training will run; restore may overwrite model id if executed after training.\")\n",
    "if DO_OFFLINE and RESTORE_OFFLINE:\n",
    "    print(\"Note: DO_OFFLINE=True but RESTORE_OFFLINE=True. Offline will run; restore may overwrite offline paths if executed after offline.\")\n",
    "\n",
    "# Soft reminder (no hard stop)\n",
    "if DO_INFERENCE and not (DO_TRAINING or RESTORE_MODEL):\n",
    "    print(\"Note: inference requires CROSS_ENCODER_MODEL_ID (from training or restore).\")\n",
    "if DO_INFERENCE and not (DO_OFFLINE or RESTORE_OFFLINE):\n",
    "    print(\"Note: inference requires offline artifacts (from offline stage, restore, or existing paths on disk).\")\n",
    "\n",
    "print(\"Flags OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f0d49",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e4704",
   "metadata": {},
   "source": [
    "## 3) Configuration (always run)\n",
    "\n",
    "This cell defines:\n",
    "- the **run directory** (`outputs/<RUN_ID>/...`) used by all stages\n",
    "- all **inputs** (ontologies, alignments)\n",
    "- all **model choices** (cross-encoder + bi-encoder + tokenizer)\n",
    "- all **canonical artifact paths** (dataset CSVs, model dir, offline bundle, inference outputs)\n",
    "\n",
    "Rule of thumb:\n",
    "- Run this cell **every time** you open the notebook.\n",
    "- You can later override specific parameters (e.g., inference top-k, custom input CSV) without changing this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION (unified training -> offline -> inference)\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "# -----------------------------\n",
    "# Run id / output layout\n",
    "# -----------------------------\n",
    "RUN_ID = f\"unified_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "OUT_DIR = Path(\"outputs\") / RUN_ID\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_DIR = OUT_DIR / \"training\"\n",
    "OFFLINE_DIR = OUT_DIR / \"offline\"\n",
    "INFER_DIR = OUT_DIR / \"inference\"\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OFFLINE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INFER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"RUN_ID:\", RUN_ID)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# Training mode and model\n",
    "# -----------------------------\n",
    "RUN_MODE = \"full\"  # \"full\" | \"build-dataset\" | \"train-only\"\n",
    "MODEL_TYPE = \"cross-encoder\"  # keep this if you want inference at the end\n",
    "MODEL_NAME = \"allenai/scibert_scivocab_uncased\"\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "HYPERPARAMETER_TUNING = False\n",
    "N_TRIALS = 5\n",
    "\n",
    "USE_FIXED_HYPERPARAMS = True\n",
    "LEARNING_RATE = 3e-5\n",
    "BATCH_SIZE = 16\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "SPLIT_RATIOS = \"0.75,0.15,0.10\"\n",
    "\n",
    "# -----------------------------\n",
    "# Inputs for dataset building\n",
    "# -----------------------------\n",
    "SRC_PATH = \"data/sweet.owl\"\n",
    "TGT_PATH = \"data/envo.owl\"\n",
    "ALIGN_PATH = \"data/envo-sweet.rdf\"\n",
    "\n",
    "SRC_PREFIX = None\n",
    "TGT_PREFIX = None  # e.g. \"http://purl.obolibrary.org/obo/ENVO_\"\n",
    "\n",
    "USE_DESCRIPTION = True\n",
    "USE_SYNONYMS = True\n",
    "USE_PARENTS = True\n",
    "USE_EQUIVALENT = True\n",
    "USE_DISJOINT = True\n",
    "\n",
    "VISUALIZE = False\n",
    "\n",
    "# -----------------------------\n",
    "# Canonical outputs of STEP 1\n",
    "# -----------------------------\n",
    "OUT_SRC_CSV = str(TRAIN_DIR / \"source_ontology.csv\")\n",
    "OUT_TGT_CSV = str(TRAIN_DIR / \"target_ontology.csv\")\n",
    "OUT_DATASET_CSV = str(TRAIN_DIR / \"training_dataset.csv\")\n",
    "\n",
    "TRAIN_SPLIT_CSV = str(Path(OUT_DATASET_CSV).with_suffix(\".train.csv\"))\n",
    "VAL_SPLIT_CSV   = str(Path(OUT_DATASET_CSV).with_suffix(\".val.csv\"))\n",
    "TEST_SPLIT_CSV  = str(Path(OUT_DATASET_CSV).with_suffix(\".test.csv\"))\n",
    "\n",
    "# train-only mode\n",
    "DATASET_CSV = TRAIN_SPLIT_CSV\n",
    "\n",
    "# model outputs\n",
    "MODEL_OUT_DIR = str(TRAIN_DIR / \"models\" / f\"{MODEL_TYPE}_custom\")\n",
    "FINAL_CROSS_ENCODER_DIR = str(Path(MODEL_OUT_DIR) / \"final_cross_encoder_model\")\n",
    "\n",
    "# -----------------------------\n",
    "# Offline bundle builder\n",
    "# -----------------------------\n",
    "OFFLINE_EXPORT_CSV = None\n",
    "OFFLINE_ONT_PATH = TGT_PATH\n",
    "OFFLINE_PREFIX = TGT_PREFIX\n",
    "\n",
    "# Tokenizer used by cross-encoder scoring (keep aligned with cross-encoder)\n",
    "CROSS_TOKENIZER_NAME = MODEL_NAME\n",
    "\n",
    "# Bi-encoder used ONLY for semantic embeddings in offline bundle / semantic retrieval\n",
    "BI_ENCODER_MODEL_ID = \"allenai/scibert_scivocab_uncased\"\n",
    "OFFLINE_SEMANTIC_BATCH_SIZE = 64\n",
    "OFFLINE_SEMANTIC_MAX_LENGTH = 256\n",
    "OFFLINE_NO_SEMANTIC_NORMALIZE = False\n",
    "\n",
    "ONTOLOGY_INTERNAL_CSV = str(OFFLINE_DIR / \"ontology_internal.csv\")\n",
    "OFFLINE_BUNDLE_PKL = str(OFFLINE_DIR / \"offline_bundle.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Inference\n",
    "# -----------------------------\n",
    "# In full pipeline: default to the trained model location.\n",
    "# In restore mode: this will be overwritten by the restore cell.\n",
    "CROSS_ENCODER_MODEL_ID = FINAL_CROSS_ENCODER_DIR\n",
    "\n",
    "INFER_INPUT_CSV = str(Path(OUT_DATASET_CSV).with_suffix(\".test.queries.csv\"))\n",
    "INFER_OUT_CSV = str(INFER_DIR / \"predictions.csv\")\n",
    "\n",
    "RETRIEVAL_COL = \"source_label\"\n",
    "SCORING_COL = \"source_text\"\n",
    "ID_COL = \"source_iri\"\n",
    "\n",
    "INFER_MODE = \"hybrid\"\n",
    "RETRIEVAL_LEXICAL_TOP_K = 100\n",
    "RETRIEVAL_SEMANTIC_TOP_K = 100\n",
    "RETRIEVAL_MERGED_TOP_K = 150\n",
    "HYBRID_RATIO_SEMANTIC = 0.5\n",
    "SEMANTIC_BATCH_SIZE = 64\n",
    "\n",
    "CROSS_TOP_K = 20\n",
    "CROSS_BATCH_SIZE = 32\n",
    "CROSS_MAX_LENGTH = 256\n",
    "\n",
    "KEEP_TOP_N = 0\n",
    "\n",
    "print(\"Config OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973492d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834164b7",
   "metadata": {},
   "source": [
    "## 4) Local restore (optional)\n",
    "\n",
    "If you already have artifacts from a previous run (local disk), you can skip rebuilding:\n",
    "\n",
    "- **Restore offline artifacts**:\n",
    "  - `offline_bundle.pkl`\n",
    "  - `ontology_internal.csv`\n",
    "\n",
    "- **Restore model artifacts**:\n",
    "  - a folder containing a saved SentenceTransformers CrossEncoder (must contain `config.json`)\n",
    "\n",
    "These cells simply **override** the paths used downstream.\n",
    "If you are running the full pipeline today, you can skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# RESTORE OFFLINE ARTIFACTS (local)\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "\n",
    "if not RESTORE_OFFLINE:\n",
    "    print(\"Skipping offline restore (RESTORE_OFFLINE=False).\")\n",
    "else:\n",
    "    # Point to a directory that contains offline_bundle.pkl and ontology_internal.csv\n",
    "    # Example:\n",
    "    # OFFLINE_RESTORE_SRC = \"outputs/unified_run_20260101_120000/offline\"\n",
    "    OFFLINE_RESTORE_SRC = None  # <-- set me\n",
    "\n",
    "    if not OFFLINE_RESTORE_SRC:\n",
    "        raise ValueError(\"Set OFFLINE_RESTORE_SRC to a folder containing offline_bundle.pkl and ontology_internal.csv\")\n",
    "\n",
    "    restore_root = Path(OFFLINE_RESTORE_SRC).expanduser().resolve()\n",
    "    if not restore_root.exists():\n",
    "        raise FileNotFoundError(f\"OFFLINE_RESTORE_SRC not found: {restore_root}\")\n",
    "\n",
    "    bundle_pkl = next(iter(restore_root.rglob(\"offline_bundle.pkl\")), None)\n",
    "    onto_csv   = next(iter(restore_root.rglob(\"ontology_internal.csv\")), None)\n",
    "\n",
    "    if bundle_pkl is None or onto_csv is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find offline_bundle.pkl and/or ontology_internal.csv under: {restore_root}\"\n",
    "        )\n",
    "\n",
    "    OFFLINE_BUNDLE_PKL = str(bundle_pkl)\n",
    "    ONTOLOGY_INTERNAL_CSV = str(onto_csv)\n",
    "\n",
    "    print(\"Restored offline artifacts:\")\n",
    "    print(\"   OFFLINE_BUNDLE_PKL    =\", OFFLINE_BUNDLE_PKL)\n",
    "    print(\"   ONTOLOGY_INTERNAL_CSV =\", ONTOLOGY_INTERNAL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# RESTORE MODEL ARTIFACTS (local)\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "\n",
    "if not RESTORE_MODEL:\n",
    "    print(\"Skipping model restore (RESTORE_MODEL=False).\")\n",
    "else:\n",
    "    # Point to a directory that is the saved CrossEncoder folder (contains config.json),\n",
    "    # OR a parent directory that contains such a folder.\n",
    "    # Example:\n",
    "    # MODEL_RESTORE_SRC = \"outputs/unified_run_20260101_120000/training/models/cross-encoder_custom/final_cross_encoder_model\"\n",
    "    MODEL_RESTORE_SRC = None  # <-- set me\n",
    "\n",
    "    if not MODEL_RESTORE_SRC:\n",
    "        raise ValueError(\"Set MODEL_RESTORE_SRC to a saved CrossEncoder folder (or a parent folder containing it).\")\n",
    "\n",
    "    restore_root = Path(MODEL_RESTORE_SRC).expanduser().resolve()\n",
    "    if not restore_root.exists():\n",
    "        raise FileNotFoundError(f\"MODEL_RESTORE_SRC not found: {restore_root}\")\n",
    "\n",
    "    def _find_cross_encoder_dir(root: Path) -> Path:\n",
    "        if (root / \"config.json\").exists():\n",
    "            return root\n",
    "        candidates = list(root.rglob(\"config.json\"))\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(f\"Could not find config.json under: {root}\")\n",
    "        return candidates[0].parent\n",
    "\n",
    "    cross_dir = _find_cross_encoder_dir(restore_root)\n",
    "    CROSS_ENCODER_MODEL_ID = str(cross_dir)\n",
    "\n",
    "    print(\"Restored cross-encoder model dir:\")\n",
    "    print(\"   CROSS_ENCODER_MODEL_ID =\", CROSS_ENCODER_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b389df4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b45ac6",
   "metadata": {},
   "source": [
    "## 5) Run pipeline (Training → Offline → Inference)\n",
    "\n",
    "This cell executes the stages selected by `DO_TRAINING`, `DO_OFFLINE`, `DO_INFERENCE`.\n",
    "\n",
    "- Each stage writes a log file under the current run folder.\n",
    "- If a stage fails, the notebook prints the last lines of the log and stops.\n",
    "- Artifact paths come from **Configuration**, unless overridden by **Restore** cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# RUN PIPELINE (training -> offline -> inference)\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Guardrails (hard)\n",
    "if RUN_MODE == \"full\" and MODEL_TYPE != \"cross-encoder\":\n",
    "    raise ValueError(\"RUN_MODE='full' ends with inference => needs MODEL_TYPE='cross-encoder'.\")\n",
    "if HYPERPARAMETER_TUNING and RUN_MODE != \"full\":\n",
    "    raise ValueError(\"--tune only allowed in RUN_MODE='full'.\")\n",
    "\n",
    "Path(MODEL_OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# STAGE 1) TRAINING (+dataset)\n",
    "# -----------------------------\n",
    "if not DO_TRAINING:\n",
    "    print(\"Skipping training (DO_TRAINING=False).\")\n",
    "else:\n",
    "    train_log = TRAIN_DIR / \"training.log\"\n",
    "    train_cmd = [\"python\", \"training.py\", \"--mode\", RUN_MODE]\n",
    "\n",
    "    if RUN_MODE in {\"full\", \"build-dataset\"}:\n",
    "        train_cmd += [\"--src\", SRC_PATH, \"--tgt\", TGT_PATH, \"--align\", ALIGN_PATH]\n",
    "        train_cmd += [\"--out-src\", OUT_SRC_CSV, \"--out-tgt\", OUT_TGT_CSV, \"--out-dataset\", OUT_DATASET_CSV]\n",
    "        train_cmd += [\"--split-ratios\", SPLIT_RATIOS]\n",
    "\n",
    "        if SRC_PREFIX:\n",
    "            train_cmd += [\"--src-prefix\", SRC_PREFIX]\n",
    "        if TGT_PREFIX:\n",
    "            train_cmd += [\"--tgt-prefix\", TGT_PREFIX]\n",
    "\n",
    "        if USE_DESCRIPTION: train_cmd.append(\"--src-use-description\")\n",
    "        if USE_SYNONYMS: train_cmd.append(\"--src-use-synonyms\")\n",
    "        if USE_PARENTS: train_cmd.append(\"--src-use-parents\")\n",
    "        if USE_EQUIVALENT: train_cmd.append(\"--src-use-equivalent\")\n",
    "        if USE_DISJOINT: train_cmd.append(\"--src-use-disjoint\")\n",
    "        if VISUALIZE: train_cmd.append(\"--visualize-alignments\")\n",
    "\n",
    "    if RUN_MODE in {\"full\", \"train-only\"}:\n",
    "        train_cmd += [\"--model-type\", MODEL_TYPE, \"--model-name\", MODEL_NAME, \"--model-output-dir\", MODEL_OUT_DIR]\n",
    "        train_cmd += [\"--num-epochs\", str(NUM_EPOCHS)]\n",
    "\n",
    "        if HYPERPARAMETER_TUNING:\n",
    "            train_cmd += [\"--tune\", \"--n-trials\", str(N_TRIALS)]\n",
    "        elif USE_FIXED_HYPERPARAMS:\n",
    "            train_cmd += [\"--learning-rate\", str(LEARNING_RATE)]\n",
    "            train_cmd += [\"--batch-size\", str(BATCH_SIZE)]\n",
    "            train_cmd += [\"--weight-decay\", str(WEIGHT_DECAY)]\n",
    "\n",
    "    if RUN_MODE == \"train-only\":\n",
    "        train_cmd += [\"--dataset-csv\", DATASET_CSV]\n",
    "\n",
    "    run_cmd(train_cmd, train_log, cwd=REPO_ROOT)\n",
    "\n",
    "    print(\"\\nTraining completed.\")\n",
    "    print(\"Dataset CSV:\", OUT_DATASET_CSV)\n",
    "    print(\"Train split:\", TRAIN_SPLIT_CSV)\n",
    "    print(\"Val split:\", VAL_SPLIT_CSV)\n",
    "    print(\"Test split:\", TEST_SPLIT_CSV)\n",
    "    print(\"Cross-encoder dir:\", FINAL_CROSS_ENCODER_DIR)\n",
    "\n",
    "    # In full pipeline, inference uses the newly trained model (unless overwritten later by restore)\n",
    "    CROSS_ENCODER_MODEL_ID = FINAL_CROSS_ENCODER_DIR\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# STAGE 2) OFFLINE BUNDLE\n",
    "# -----------------------------\n",
    "if not DO_OFFLINE:\n",
    "    print(\"Skipping offline bundle (DO_OFFLINE=False).\")\n",
    "else:\n",
    "    offline_log = OFFLINE_DIR / \"offline_bundle.log\"\n",
    "    offline_cmd = [\n",
    "        \"python\", \"build_ontology_bundle.py\",\n",
    "        \"--out-csv\", ONTOLOGY_INTERNAL_CSV,\n",
    "        \"--out-bundle\", OFFLINE_BUNDLE_PKL,\n",
    "        \"--tokenizer-name\", CROSS_TOKENIZER_NAME,\n",
    "        \"--bi-encoder-model-id\", BI_ENCODER_MODEL_ID,\n",
    "        \"--semantic-batch-size\", str(OFFLINE_SEMANTIC_BATCH_SIZE),\n",
    "        \"--semantic-max-length\", str(OFFLINE_SEMANTIC_MAX_LENGTH),\n",
    "    ]\n",
    "    if OFFLINE_NO_SEMANTIC_NORMALIZE:\n",
    "        offline_cmd.append(\"--no-semantic-normalize\")\n",
    "\n",
    "    if OFFLINE_EXPORT_CSV:\n",
    "        offline_cmd += [\"--export-csv\", OFFLINE_EXPORT_CSV]\n",
    "    else:\n",
    "        offline_cmd += [\"--ont-path\", OFFLINE_ONT_PATH]\n",
    "        if OFFLINE_PREFIX:\n",
    "            offline_cmd += [\"--prefix\", OFFLINE_PREFIX]\n",
    "\n",
    "    run_cmd(offline_cmd, offline_log, cwd=REPO_ROOT)\n",
    "\n",
    "    print(\"\\nOffline bundle completed.\")\n",
    "    print(\"Ontology internal CSV:\", ONTOLOGY_INTERNAL_CSV)\n",
    "    print(\"Offline bundle PKL:\", OFFLINE_BUNDLE_PKL)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# STAGE 3) INFERENCE\n",
    "# -----------------------------\n",
    "if not DO_INFERENCE:\n",
    "    print(\"Skipping inference (DO_INFERENCE=False).\")\n",
    "else:\n",
    "    # Final sanity checks (runtime)\n",
    "    if \"CROSS_ENCODER_MODEL_ID\" not in globals() or CROSS_ENCODER_MODEL_ID is None:\n",
    "        raise ValueError(\n",
    "            \"CROSS_ENCODER_MODEL_ID is not set. \"\n",
    "            \"Run training (DO_TRAINING=True) or restore model (RESTORE_MODEL=True).\"\n",
    "        )\n",
    "\n",
    "    if not Path(OFFLINE_BUNDLE_PKL).exists():\n",
    "        raise FileNotFoundError(f\"OFFLINE_BUNDLE_PKL not found: {OFFLINE_BUNDLE_PKL}\")\n",
    "    if not Path(ONTOLOGY_INTERNAL_CSV).exists():\n",
    "        raise FileNotFoundError(f\"ONTOLOGY_INTERNAL_CSV not found: {ONTOLOGY_INTERNAL_CSV}\")\n",
    "    if not Path(INFER_INPUT_CSV).exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"INFER_INPUT_CSV not found: {INFER_INPUT_CSV}\\n\"\n",
    "            \"In full/build-dataset mode, training should generate *.test.queries.csv. \"\n",
    "            \"Otherwise set INFER_INPUT_CSV to your custom file.\"\n",
    "        )\n",
    "\n",
    "    infer_log = INFER_DIR / \"inference.log\"\n",
    "    infer_cmd = [\n",
    "        \"python\", \"run_inference.py\",\n",
    "        \"--bundle\", OFFLINE_BUNDLE_PKL,\n",
    "        \"--ontology-csv\", ONTOLOGY_INTERNAL_CSV,\n",
    "        \"--input-csv\", INFER_INPUT_CSV,\n",
    "        \"--out-csv\", INFER_OUT_CSV,\n",
    "        \"--mode\", INFER_MODE,\n",
    "        \"--cross-tokenizer-name\", CROSS_TOKENIZER_NAME,\n",
    "        \"--cross-encoder-model-id\", CROSS_ENCODER_MODEL_ID,\n",
    "        \"--retrieval-col\", RETRIEVAL_COL,\n",
    "        \"--retrieval-lexical-top-k\", str(RETRIEVAL_LEXICAL_TOP_K),\n",
    "        \"--retrieval-semantic-top-k\", str(RETRIEVAL_SEMANTIC_TOP_K),\n",
    "        \"--retrieval-merged-top-k\", str(RETRIEVAL_MERGED_TOP_K),\n",
    "        \"--hybrid-ratio-semantic\", str(HYBRID_RATIO_SEMANTIC),\n",
    "        \"--semantic-batch-size\", str(SEMANTIC_BATCH_SIZE),\n",
    "        \"--cross-top-k\", str(CROSS_TOP_K),\n",
    "        \"--cross-batch-size\", str(CROSS_BATCH_SIZE),\n",
    "        \"--cross-max-length\", str(CROSS_MAX_LENGTH),\n",
    "        \"--keep-top-n\", str(KEEP_TOP_N),\n",
    "    ]\n",
    "    if SCORING_COL:\n",
    "        infer_cmd += [\"--scoring-col\", SCORING_COL]\n",
    "    if ID_COL:\n",
    "        infer_cmd += [\"--id-col\", ID_COL]\n",
    "\n",
    "    run_cmd(infer_cmd, infer_log, cwd=REPO_ROOT)\n",
    "\n",
    "    print(\"\\nInference completed.\")\n",
    "    print(\"Predictions CSV:\", INFER_OUT_CSV)\n",
    "\n",
    "print(\"\\nPipeline cell finished.\")\n",
    "print(\"Run folder:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbd2e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98abd88",
   "metadata": {},
   "source": [
    "## 6) Export helpers (ALWAYS RUN)\n",
    "\n",
    "All export cells use the same design:\n",
    "\n",
    "- Every ZIP contains the requested artifacts **plus** a `config.txt` snapshot.\n",
    "- `config.txt` is generated at export time.\n",
    "\n",
    ">ZIPs are created on disk and the path is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT HELPERS (config.txt + zip) — LOCAL\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "\n",
    "def write_config_txt(config_dir: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Writes a config.txt snapshot of the current effective configuration.\n",
    "    This is intended to be called right before exporting ZIP artifacts.\n",
    "    \"\"\"\n",
    "    config_dir = Path(config_dir)\n",
    "    config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    lines = [\n",
    "        \"# Ontology Alignment – Run Configuration\",\n",
    "        f\"# Generated on: {datetime.now().isoformat()}\",\n",
    "        \"\",\n",
    "        \"[Run]\",\n",
    "        f\"RUN_ID = {globals().get('RUN_ID', None)}\",\n",
    "        f\"OUT_DIR = {globals().get('OUT_DIR', None)}\",\n",
    "        f\"RUN_MODE = {globals().get('RUN_MODE', None)}\",\n",
    "        \"\",\n",
    "        \"[Model]\",\n",
    "        f\"MODEL_TYPE = {globals().get('MODEL_TYPE', None)}\",\n",
    "        f\"MODEL_NAME = {globals().get('MODEL_NAME', None)}\",\n",
    "        f\"CROSS_ENCODER_MODEL_ID = {globals().get('CROSS_ENCODER_MODEL_ID', None)}\",\n",
    "        f\"BI_ENCODER_MODEL_ID = {globals().get('BI_ENCODER_MODEL_ID', None)}\",\n",
    "        f\"CROSS_TOKENIZER_NAME = {globals().get('CROSS_TOKENIZER_NAME', None)}\",\n",
    "        \"\",\n",
    "        \"[Training]\",\n",
    "        f\"NUM_EPOCHS = {globals().get('NUM_EPOCHS', None)}\",\n",
    "        f\"LEARNING_RATE = {globals().get('LEARNING_RATE', None)}\",\n",
    "        f\"BATCH_SIZE = {globals().get('BATCH_SIZE', None)}\",\n",
    "        f\"WEIGHT_DECAY = {globals().get('WEIGHT_DECAY', None)}\",\n",
    "        f\"SPLIT_RATIOS = {globals().get('SPLIT_RATIOS', None)}\",\n",
    "        \"\",\n",
    "        \"[Offline]\",\n",
    "        f\"OFFLINE_ONT_PATH = {globals().get('OFFLINE_ONT_PATH', None)}\",\n",
    "        f\"OFFLINE_PREFIX = {globals().get('OFFLINE_PREFIX', None)}\",\n",
    "        f\"OFFLINE_SEMANTIC_BATCH_SIZE = {globals().get('OFFLINE_SEMANTIC_BATCH_SIZE', None)}\",\n",
    "        f\"OFFLINE_SEMANTIC_MAX_LENGTH = {globals().get('OFFLINE_SEMANTIC_MAX_LENGTH', None)}\",\n",
    "        f\"OFFLINE_NO_SEMANTIC_NORMALIZE = {globals().get('OFFLINE_NO_SEMANTIC_NORMALIZE', None)}\",\n",
    "        f\"OFFLINE_BUNDLE_PKL = {globals().get('OFFLINE_BUNDLE_PKL', None)}\",\n",
    "        f\"ONTOLOGY_INTERNAL_CSV = {globals().get('ONTOLOGY_INTERNAL_CSV', None)}\",\n",
    "        \"\",\n",
    "        \"[Inference]\",\n",
    "        f\"INFER_MODE = {globals().get('INFER_MODE', None)}\",\n",
    "        f\"INFER_INPUT_CSV = {globals().get('INFER_INPUT_CSV', None)}\",\n",
    "        f\"INFER_OUT_CSV = {globals().get('INFER_OUT_CSV', None)}\",\n",
    "        f\"RETRIEVAL_COL = {globals().get('RETRIEVAL_COL', None)}\",\n",
    "        f\"SCORING_COL = {globals().get('SCORING_COL', None)}\",\n",
    "        f\"ID_COL = {globals().get('ID_COL', None)}\",\n",
    "        f\"RETRIEVAL_LEXICAL_TOP_K = {globals().get('RETRIEVAL_LEXICAL_TOP_K', None)}\",\n",
    "        f\"RETRIEVAL_SEMANTIC_TOP_K = {globals().get('RETRIEVAL_SEMANTIC_TOP_K', None)}\",\n",
    "        f\"RETRIEVAL_MERGED_TOP_K = {globals().get('RETRIEVAL_MERGED_TOP_K', None)}\",\n",
    "        f\"HYBRID_RATIO_SEMANTIC = {globals().get('HYBRID_RATIO_SEMANTIC', None)}\",\n",
    "        f\"SEMANTIC_BATCH_SIZE = {globals().get('SEMANTIC_BATCH_SIZE', None)}\",\n",
    "        f\"CROSS_TOP_K = {globals().get('CROSS_TOP_K', None)}\",\n",
    "        f\"CROSS_BATCH_SIZE = {globals().get('CROSS_BATCH_SIZE', None)}\",\n",
    "        f\"CROSS_MAX_LENGTH = {globals().get('CROSS_MAX_LENGTH', None)}\",\n",
    "        f\"KEEP_TOP_N = {globals().get('KEEP_TOP_N', None)}\",\n",
    "    ]\n",
    "\n",
    "    config_path = config_dir / \"config.txt\"\n",
    "    config_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    return config_path\n",
    "\n",
    "\n",
    "def make_zip_with_config(\n",
    "    zip_path: Path,\n",
    "    files_to_include: list[Path],\n",
    "    config_dir: Path | None = None,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Creates a ZIP containing existing artifacts + a config.txt snapshot.\n",
    "    Returns the created zip path.\n",
    "    \"\"\"\n",
    "    zip_path = Path(zip_path)\n",
    "    zip_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if config_dir is None:\n",
    "        config_dir = zip_path.parent\n",
    "    config_path = write_config_txt(Path(config_dir))\n",
    "\n",
    "    existing = [Path(p) for p in files_to_include if Path(p).exists()]\n",
    "    if not existing:\n",
    "        raise FileNotFoundError(\"None of the requested files exist. Nothing to zip.\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "        for p in existing:\n",
    "            z.write(p, arcname=p.name)\n",
    "        z.write(config_path, arcname=\"config.txt\")\n",
    "\n",
    "    print(\"Created ZIP:\", zip_path)\n",
    "    print(\"Included:\", [p.name for p in existing], \"+ config.txt\")\n",
    "    return zip_path\n",
    "\n",
    "\n",
    "print(\"Export helpers ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f588931",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e45f67",
   "metadata": {},
   "source": [
    "## 7.1) Export inference outputs + gold (full pipeline)\n",
    "\n",
    "This is a **result extraction** utility intended for the **full pipeline** case:\n",
    "\n",
    "- `predictions.csv` must exist (produced by inference)\n",
    "- `*.test.gold.csv` must exist (produced during dataset build/split)\n",
    "\n",
    "It creates a single ZIP containing:\n",
    "- `predictions.csv`\n",
    "- `*.test.gold.csv`\n",
    "- `config.txt` (effective run config snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c441a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT ARTIFACTS (predictions + gold) — LOCAL\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pred_path = Path(INFER_OUT_CSV)\n",
    "gold_path = Path(str(Path(OUT_DATASET_CSV).with_suffix(\".test.gold.csv\")))\n",
    "\n",
    "missing = [str(p) for p in [pred_path, gold_path] if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required file(s):\\n\"\n",
    "        + \"\\n\".join(f\" - {m}\" for m in missing)\n",
    "        + \"\\n\\nNotes:\\n\"\n",
    "        \" - predictions.csv is produced by the inference stage.\\n\"\n",
    "        \" - *.test.gold.csv is produced during dataset construction/splitting.\\n\"\n",
    "    )\n",
    "\n",
    "zip_path = pred_path.parent / \"predictions_and_gold.zip\"\n",
    "make_zip_with_config(zip_path, [pred_path, gold_path], config_dir=pred_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d41e49",
   "metadata": {},
   "source": [
    "## 7.2) Export predictions + optional gold\n",
    "\n",
    "This export cell works in both scenarios:\n",
    "\n",
    "- Full pipeline: gold is auto-detected (`*.test.gold.csv`)\n",
    "- Inference-only: gold may be missing (that's fine), or you can provide a custom gold path\n",
    "\n",
    "It creates a ZIP containing:\n",
    "- `predictions.csv`\n",
    "- (optional) gold CSV if available\n",
    "- `config.txt` (effective run config snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT ARTIFACTS (predictions + optional gold) — LOCAL\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional: if you have an external gold file, set it here\n",
    "GOLD_PATH_OVERRIDE = None  # e.g. \"my_eval/gold_truth.csv\"\n",
    "\n",
    "pred_path = Path(INFER_OUT_CSV)\n",
    "if not pred_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"predictions file not found:\\n - {pred_path}\\n\\n\"\n",
    "        \"Run inference first or set INFER_OUT_CSV correctly.\"\n",
    "    )\n",
    "\n",
    "gold_candidates = []\n",
    "if GOLD_PATH_OVERRIDE is not None:\n",
    "    gold_candidates.append(Path(GOLD_PATH_OVERRIDE))\n",
    "\n",
    "gold_candidates.append(Path(str(Path(OUT_DATASET_CSV).with_suffix(\".test.gold.csv\"))))\n",
    "\n",
    "gold_path = next((p for p in gold_candidates if p.exists()), None)\n",
    "\n",
    "files_to_zip = [pred_path]\n",
    "zip_name = \"predictions_only.zip\"\n",
    "\n",
    "if gold_path is not None:\n",
    "    files_to_zip.append(gold_path)\n",
    "    zip_name = \"predictions_and_gold.zip\"\n",
    "    print(\"Found gold:\", gold_path)\n",
    "else:\n",
    "    print(\"Gold not found (OK). Tried:\")\n",
    "    for p in gold_candidates:\n",
    "        print(\" -\", p)\n",
    "\n",
    "zip_path = pred_path.parent / zip_name\n",
    "make_zip_with_config(zip_path, files_to_zip, config_dir=pred_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb75ae",
   "metadata": {},
   "source": [
    "## 7.3) Export the entire run folder (everything)\n",
    "\n",
    "This creates a ZIP archive of the whole `OUT_DIR` folder (training logs, models, offline bundle, inference outputs, etc.)\n",
    "and also drops a `config.txt` snapshot inside the run folder before zipping.\n",
    "\n",
    "Use this when you want to share or archive the entire run in one shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6725b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT FULL RUN DIR (OUT_DIR) — LOCAL\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "out_dir = Path(OUT_DIR)\n",
    "if not out_dir.exists():\n",
    "    raise FileNotFoundError(f\"OUT_DIR not found: {out_dir}\")\n",
    "\n",
    "# Ensure config.txt exists inside OUT_DIR before zipping\n",
    "_ = write_config_txt(out_dir)\n",
    "\n",
    "zip_base = str(out_dir)  # shutil.make_archive wants a string base path (without .zip)\n",
    "zip_path = zip_base + \".zip\"\n",
    "\n",
    "print(\"Zipping:\", out_dir, \"->\", zip_path)\n",
    "shutil.make_archive(zip_base, \"zip\", root_dir=str(out_dir))\n",
    "print(\"Created:\", zip_path)\n",
    "print(\"Note: ZIP includes config.txt at the root of OUT_DIR.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fbd9d0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa7c47",
   "metadata": {},
   "source": [
    "## 8) Quick sanity checks and pointers\n",
    "\n",
    "These cells are lightweight helpers that run **after** the pipeline.\n",
    "\n",
    "They do not recompute anything:\n",
    "- they check that key artifacts exist\n",
    "- they print the most important paths (model, offline bundle, predictions)\n",
    "- they optionally preview a few rows of the output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# POST-RUN SUMMARY (paths + existence)\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def _exists(p: str | Path) -> bool:\n",
    "    return Path(p).exists()\n",
    "\n",
    "print(\"\\n=== RUN SUMMARY ===\")\n",
    "print(\"RUN_ID:\", RUN_ID)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "print(\"\\n--- Training ---\")\n",
    "print(\"OUT_DATASET_CSV:\", OUT_DATASET_CSV, \"| exists =\", _exists(OUT_DATASET_CSV))\n",
    "print(\"TRAIN_SPLIT_CSV:\", TRAIN_SPLIT_CSV, \"| exists =\", _exists(TRAIN_SPLIT_CSV))\n",
    "print(\"VAL_SPLIT_CSV  :\", VAL_SPLIT_CSV,   \"| exists =\", _exists(VAL_SPLIT_CSV))\n",
    "print(\"TEST_SPLIT_CSV :\", TEST_SPLIT_CSV,  \"| exists =\", _exists(TEST_SPLIT_CSV))\n",
    "print(\"CROSS_ENCODER_MODEL_ID:\", CROSS_ENCODER_MODEL_ID, \"| exists =\", _exists(CROSS_ENCODER_MODEL_ID))\n",
    "\n",
    "print(\"\\n--- Offline ---\")\n",
    "print(\"OFFLINE_BUNDLE_PKL   :\", OFFLINE_BUNDLE_PKL, \"| exists =\", _exists(OFFLINE_BUNDLE_PKL))\n",
    "print(\"ONTOLOGY_INTERNAL_CSV:\", ONTOLOGY_INTERNAL_CSV, \"| exists =\", _exists(ONTOLOGY_INTERNAL_CSV))\n",
    "\n",
    "print(\"\\n--- Inference ---\")\n",
    "print(\"INFER_INPUT_CSV:\", INFER_INPUT_CSV, \"| exists =\", _exists(INFER_INPUT_CSV))\n",
    "print(\"INFER_OUT_CSV  :\", INFER_OUT_CSV,   \"| exists =\", _exists(INFER_OUT_CSV))\n",
    "\n",
    "print(\"\\n--- Exports ---\")\n",
    "exports_dir = Path(OUT_DIR) / \"exports\"\n",
    "print(\"Exports dir:\", exports_dir, \"| exists =\", exports_dir.exists())\n",
    "if exports_dir.exists():\n",
    "    zips = sorted([p.name for p in exports_dir.glob(\"*.zip\")])\n",
    "    print(\"ZIPs:\", zips if zips else \"(none yet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a64d44",
   "metadata": {},
   "source": [
    "### 8.1) Preview `predictions.csv` (optional)\n",
    "\n",
    "This is a convenience cell to quickly inspect a few rows of the inference output locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PREVIEW PREDICTIONS (optional)\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None\n",
    "\n",
    "pred_path = Path(INFER_OUT_CSV)\n",
    "\n",
    "if not pred_path.exists():\n",
    "    print(\"Predictions not found:\", pred_path)\n",
    "elif pd is None:\n",
    "    print(\"pandas is not installed. Install with: pip install pandas\")\n",
    "else:\n",
    "    df = pd.read_csv(pred_path)\n",
    "    print(\"Predictions shape:\", df.shape)\n",
    "    display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15531d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011492e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae922a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f14b8",
   "metadata": {},
   "source": [
    "## A) Stage-by-stage execution (local)\n",
    "\n",
    "This section runs the pipeline **stage by stage**, controlled by the flags in the\n",
    "**RUN MODE FLAGS** cell.\n",
    "\n",
    "The execution logic is:\n",
    "\n",
    "- **Training stage**\n",
    "  - Runs only if `DO_TRAINING=True`\n",
    "  - Produces:\n",
    "    - dataset CSVs and splits\n",
    "    - a trained cross-encoder model\n",
    "  - If training runs, it sets `CROSS_ENCODER_MODEL_ID` automatically\n",
    "\n",
    "- **Offline bundle stage**\n",
    "  - Runs only if `DO_OFFLINE=True`\n",
    "  - Produces:\n",
    "    - `ontology_internal.csv`\n",
    "    - `offline_bundle.pkl`\n",
    "\n",
    "- **Inference stage**\n",
    "  - Runs only if `DO_INFERENCE=True`\n",
    "  - Requires:\n",
    "    - a valid `CROSS_ENCODER_MODEL_ID`\n",
    "      (from training or restore)\n",
    "    - valid offline artifacts\n",
    "      (from offline stage, restore, or existing paths)\n",
    "\n",
    "Restore cells (if enabled) simply **override paths** used by these stages.\n",
    "They do not execute any computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36db27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STAGE 1 — TRAINING (+ dataset construction)\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "if not DO_TRAINING:\n",
    "    print(\"Skipping training stage (DO_TRAINING=False).\")\n",
    "else:\n",
    "    train_log = TRAIN_DIR / \"training.log\"\n",
    "    train_cmd = [\"python\", \"training.py\", \"--mode\", RUN_MODE]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Dataset construction\n",
    "    # -----------------------------\n",
    "    if RUN_MODE in {\"full\", \"build-dataset\"}:\n",
    "        train_cmd += [\n",
    "            \"--src\", SRC_PATH,\n",
    "            \"--tgt\", TGT_PATH,\n",
    "            \"--align\", ALIGN_PATH,\n",
    "            \"--out-src\", OUT_SRC_CSV,\n",
    "            \"--out-tgt\", OUT_TGT_CSV,\n",
    "            \"--out-dataset\", OUT_DATASET_CSV,\n",
    "            \"--split-ratios\", SPLIT_RATIOS,\n",
    "        ]\n",
    "\n",
    "        if SRC_PREFIX:\n",
    "            train_cmd += [\"--src-prefix\", SRC_PREFIX]\n",
    "        if TGT_PREFIX:\n",
    "            train_cmd += [\"--tgt-prefix\", TGT_PREFIX]\n",
    "\n",
    "        if USE_DESCRIPTION: train_cmd.append(\"--src-use-description\")\n",
    "        if USE_SYNONYMS: train_cmd.append(\"--src-use-synonyms\")\n",
    "        if USE_PARENTS: train_cmd.append(\"--src-use-parents\")\n",
    "        if USE_EQUIVALENT: train_cmd.append(\"--src-use-equivalent\")\n",
    "        if USE_DISJOINT: train_cmd.append(\"--src-use-disjoint\")\n",
    "        if VISUALIZE: train_cmd.append(\"--visualize-alignments\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Model training\n",
    "    # -----------------------------\n",
    "    if RUN_MODE in {\"full\", \"train-only\"}:\n",
    "        Path(MODEL_OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        train_cmd += [\n",
    "            \"--model-type\", MODEL_TYPE,\n",
    "            \"--model-name\", MODEL_NAME,\n",
    "            \"--model-output-dir\", MODEL_OUT_DIR,\n",
    "            \"--num-epochs\", str(NUM_EPOCHS),\n",
    "        ]\n",
    "\n",
    "        if HYPERPARAMETER_TUNING:\n",
    "            train_cmd += [\"--tune\", \"--n-trials\", str(N_TRIALS)]\n",
    "        elif USE_FIXED_HYPERPARAMS:\n",
    "            train_cmd += [\n",
    "                \"--learning-rate\", str(LEARNING_RATE),\n",
    "                \"--batch-size\", str(BATCH_SIZE),\n",
    "                \"--weight-decay\", str(WEIGHT_DECAY),\n",
    "            ]\n",
    "\n",
    "    if RUN_MODE == \"train-only\":\n",
    "        train_cmd += [\"--dataset-csv\", DATASET_CSV]\n",
    "\n",
    "    run_cmd(train_cmd, train_log, cwd=REPO_ROOT)\n",
    "\n",
    "    print(\"\\nTraining stage completed.\")\n",
    "    print(\"Dataset CSV:\", OUT_DATASET_CSV)\n",
    "    print(\"Cross-encoder output dir:\", FINAL_CROSS_ENCODER_DIR)\n",
    "\n",
    "    # In a full run, the freshly trained model becomes the default for inference\n",
    "    CROSS_ENCODER_MODEL_ID = FINAL_CROSS_ENCODER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STAGE 2 — OFFLINE BUNDLE\n",
    "# ============================================\n",
    "\n",
    "if not DO_OFFLINE:\n",
    "    print(\"Skipping offline bundle stage (DO_OFFLINE=False).\")\n",
    "else:\n",
    "    offline_log = OFFLINE_DIR / \"offline_bundle.log\"\n",
    "\n",
    "    offline_cmd = [\n",
    "        \"python\", \"build_ontology_bundle.py\",\n",
    "        \"--out-csv\", ONTOLOGY_INTERNAL_CSV,\n",
    "        \"--out-bundle\", OFFLINE_BUNDLE_PKL,\n",
    "        \"--tokenizer-name\", CROSS_TOKENIZER_NAME,\n",
    "        \"--bi-encoder-model-id\", BI_ENCODER_MODEL_ID,\n",
    "        \"--semantic-batch-size\", str(OFFLINE_SEMANTIC_BATCH_SIZE),\n",
    "        \"--semantic-max-length\", str(OFFLINE_SEMANTIC_MAX_LENGTH),\n",
    "    ]\n",
    "\n",
    "    if OFFLINE_NO_SEMANTIC_NORMALIZE:\n",
    "        offline_cmd.append(\"--no-semantic-normalize\")\n",
    "\n",
    "    if OFFLINE_EXPORT_CSV:\n",
    "        offline_cmd += [\"--export-csv\", OFFLINE_EXPORT_CSV]\n",
    "    else:\n",
    "        offline_cmd += [\"--ont-path\", OFFLINE_ONT_PATH]\n",
    "        if OFFLINE_PREFIX:\n",
    "            offline_cmd += [\"--prefix\", OFFLINE_PREFIX]\n",
    "\n",
    "    run_cmd(offline_cmd, offline_log, cwd=REPO_ROOT)\n",
    "\n",
    "    print(\"\\nOffline bundle stage completed.\")\n",
    "    print(\"Ontology internal CSV:\", ONTOLOGY_INTERNAL_CSV)\n",
    "    print(\"Offline bundle PKL:\", OFFLINE_BUNDLE_PKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2719915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STAGE 3 — INFERENCE\n",
    "# ============================================\n",
    "\n",
    "if not DO_INFERENCE:\n",
    "    print(\"Skipping inference stage (DO_INFERENCE=False).\")\n",
    "else:\n",
    "    # -----------------------------\n",
    "    # Runtime sanity checks\n",
    "    # -----------------------------\n",
    "    if \"CROSS_ENCODER_MODEL_ID\" not in globals() or CROSS_ENCODER_MODEL_ID is None:\n",
    "        raise ValueError(\n",
    "            \"CROSS_ENCODER_MODEL_ID is not set. \"\n",
    "            \"Run training or restore a model before inference.\"\n",
    "        )\n",
    "\n",
    "    if not Path(OFFLINE_BUNDLE_PKL).exists():\n",
    "        raise FileNotFoundError(f\"OFFLINE_BUNDLE_PKL not found: {OFFLINE_BUNDLE_PKL}\")\n",
    "\n",
    "    if not Path(ONTOLOGY_INTERNAL_CSV).exists():\n",
    "        raise FileNotFoundError(f\"ONTOLOGY_INTERNAL_CSV not found: {ONTOLOGY_INTERNAL_CSV}\")\n",
    "\n",
    "    if not Path(INFER_INPUT_CSV).exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"INFER_INPUT_CSV not found: {INFER_INPUT_CSV}\\n\"\n",
    "            \"Provide a custom input CSV or run dataset construction first.\"\n",
    "        )\n",
    "\n",
    "    infer_log = INFER_DIR / \"inference.log\"\n",
    "\n",
    "    infer_cmd = [\n",
    "        \"python\", \"run_inference.py\",\n",
    "        \"--bundle\", OFFLINE_BUNDLE_PKL,\n",
    "        \"--ontology-csv\", ONTOLOGY_INTERNAL_CSV,\n",
    "        \"--input-csv\", INFER_INPUT_CSV,\n",
    "        \"--out-csv\", INFER_OUT_CSV,\n",
    "        \"--mode\", INFER_MODE,\n",
    "        \"--cross-tokenizer-name\", CROSS_TOKENIZER_NAME,\n",
    "        \"--cross-encoder-model-id\", CROSS_ENCODER_MODEL_ID,\n",
    "        \"--retrieval-col\", RETRIEVAL_COL,\n",
    "        \"--retrieval-lexical-top-k\", str(RETRIEVAL_LEXICAL_TOP_K),\n",
    "        \"--retrieval-semantic-top-k\", str(RETRIEVAL_SEMANTIC_TOP_K),\n",
    "        \"--retrieval-merged-top-k\", str(RETRIEVAL_MERGED_TOP_K),\n",
    "        \"--hybrid-ratio-semantic\", str(HYBRID_RATIO_SEMANTIC),\n",
    "        \"--semantic-batch-size\", str(SEMANTIC_BATCH_SIZE),\n",
    "        \"--cross-top-k\", str(CROSS_TOP_K),\n",
    "        \"--cross-batch-size\", str(CROSS_BATCH_SIZE),\n",
    "        \"--cross-max-length\", str(CROSS_MAX_LENGTH),\n",
    "        \"--keep-top-n\", str(KEEP_TOP_N),\n",
    "    ]\n",
    "\n",
    "    if SCORING_COL:\n",
    "        infer_cmd += [\"--scoring-col\", SCORING_COL]\n",
    "    if ID_COL:\n",
    "        infer_cmd += [\"--id-col\", ID_COL]\n",
    "\n",
    "    run_cmd(infer_cmd, infer_log, cwd=REPO_ROOT)\n",
    "\n",
    "    print(\"\\nInference stage completed.\")\n",
    "    print(\"Predictions CSV:\", INFER_OUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff53c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a76759",
   "metadata": {},
   "source": [
    "### B) Export inference outputs (predictions + optional gold)\n",
    "\n",
    "This export creates one ZIP containing:\n",
    "- `predictions.csv`\n",
    "- (optional) gold CSV if available\n",
    "- `config.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT ARTIFACTS (predictions + optional gold) — LOCAL\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional: external gold file (if you have one)\n",
    "GOLD_PATH_OVERRIDE = None  # e.g. \"my_eval/gold_truth.csv\"\n",
    "\n",
    "pred_path = Path(INFER_OUT_CSV)\n",
    "if not pred_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"predictions file not found:\\n - {pred_path}\\n\\n\"\n",
    "        \"Run inference first or set INFER_OUT_CSV correctly.\"\n",
    "    )\n",
    "\n",
    "gold_candidates = []\n",
    "if GOLD_PATH_OVERRIDE is not None:\n",
    "    gold_candidates.append(Path(GOLD_PATH_OVERRIDE))\n",
    "\n",
    "# Default gold path from dataset build/split (full pipeline)\n",
    "gold_candidates.append(Path(str(Path(OUT_DATASET_CSV).with_suffix(\".test.gold.csv\"))))\n",
    "\n",
    "gold_path = next((p for p in gold_candidates if p.exists()), None)\n",
    "\n",
    "files_to_zip = [pred_path]\n",
    "zip_name = \"predictions_only.zip\"\n",
    "\n",
    "if gold_path is not None:\n",
    "    files_to_zip.append(gold_path)\n",
    "    zip_name = \"predictions_and_gold.zip\"\n",
    "    print(\"Found gold:\", gold_path)\n",
    "else:\n",
    "    print(\"Gold not found (OK). Tried:\")\n",
    "    for p in gold_candidates:\n",
    "        print(\" -\", p)\n",
    "\n",
    "zip_path = pred_path.parent / zip_name\n",
    "make_zip_with_config(zip_path, files_to_zip, config_dir=pred_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a26a1",
   "metadata": {},
   "source": [
    "### B.A) Export the entire run folder (`OUT_DIR`)\n",
    "\n",
    "This creates a ZIP archive of the whole `OUT_DIR` folder:\n",
    "- training logs + model artifacts\n",
    "- offline bundle artifacts\n",
    "- inference outputs\n",
    "\n",
    "A `config.txt` snapshot is written **inside `OUT_DIR`** before zipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT FULL RUN DIR (OUT_DIR) — LOCAL\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "out_dir = Path(OUT_DIR)\n",
    "if not out_dir.exists():\n",
    "    raise FileNotFoundError(f\"OUT_DIR not found: {out_dir}\")\n",
    "\n",
    "# Ensure config.txt exists inside OUT_DIR before zipping\n",
    "_ = write_config_txt(out_dir)\n",
    "\n",
    "zip_base = str(out_dir)  # shutil.make_archive wants base path (without .zip)\n",
    "zip_path = zip_base + \".zip\"\n",
    "\n",
    "print(\"Zipping:\", out_dir, \"->\", zip_path)\n",
    "shutil.make_archive(zip_base, \"zip\", root_dir=str(out_dir))\n",
    "print(\"Created:\", zip_path)\n",
    "print(\"Note: ZIP includes config.txt at the root of OUT_DIR.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe4bb7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e287973",
   "metadata": {},
   "source": [
    "## C) Quick sanity checks and pointers (post-run)\n",
    "\n",
    "These cells are lightweight helpers that run **after** the staged pipeline.\n",
    "\n",
    "They do not recompute anything:\n",
    "- they check which key artifacts exist **given the current effective paths**\n",
    "- they print the most important locations (model, offline bundle, predictions)\n",
    "- they list any created ZIP exports under `OUT_DIR/exports`\n",
    "- they optionally preview a few rows of `predictions.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e260d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# POST-RUN SUMMARY (stage-aware: paths + existence)\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def _exists(p: str | Path | None) -> bool:\n",
    "    if p is None:\n",
    "        return False\n",
    "    try:\n",
    "        return Path(p).exists()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "print(\"\\n=== RUN SUMMARY (stage-aware) ===\")\n",
    "print(\"RUN_ID :\", globals().get(\"RUN_ID\", None))\n",
    "print(\"OUT_DIR:\", globals().get(\"OUT_DIR\", None))\n",
    "\n",
    "print(\"\\nFlags:\")\n",
    "print(\"  DO_TRAINING   =\", globals().get(\"DO_TRAINING\", None))\n",
    "print(\"  DO_OFFLINE    =\", globals().get(\"DO_OFFLINE\", None))\n",
    "print(\"  DO_INFERENCE  =\", globals().get(\"DO_INFERENCE\", None))\n",
    "print(\"  RESTORE_MODEL =\", globals().get(\"RESTORE_MODEL\", None))\n",
    "print(\"  RESTORE_OFFLINE =\", globals().get(\"RESTORE_OFFLINE\", None))\n",
    "\n",
    "# -----------------------------\n",
    "# Training artifacts (optional)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Training artifacts (may be absent in stage runs) ---\")\n",
    "print(\"OUT_DATASET_CSV:\", globals().get(\"OUT_DATASET_CSV\", None), \"| exists =\", _exists(globals().get(\"OUT_DATASET_CSV\", None)))\n",
    "print(\"TRAIN_SPLIT_CSV:\", globals().get(\"TRAIN_SPLIT_CSV\", None), \"| exists =\", _exists(globals().get(\"TRAIN_SPLIT_CSV\", None)))\n",
    "print(\"VAL_SPLIT_CSV  :\", globals().get(\"VAL_SPLIT_CSV\", None),   \"| exists =\", _exists(globals().get(\"VAL_SPLIT_CSV\", None)))\n",
    "print(\"TEST_SPLIT_CSV :\", globals().get(\"TEST_SPLIT_CSV\", None),  \"| exists =\", _exists(globals().get(\"TEST_SPLIT_CSV\", None)))\n",
    "\n",
    "# Gold/queries are only guaranteed in full/build-dataset mode\n",
    "gold_path = None\n",
    "queries_path = None\n",
    "if \"OUT_DATASET_CSV\" in globals():\n",
    "    gold_path = str(Path(OUT_DATASET_CSV).with_suffix(\".test.gold.csv\"))\n",
    "    queries_path = str(Path(OUT_DATASET_CSV).with_suffix(\".test.queries.csv\"))\n",
    "\n",
    "print(\"TEST gold CSV  :\", gold_path,   \"| exists =\", _exists(gold_path))\n",
    "print(\"TEST queries CSV:\", queries_path, \"| exists =\", _exists(queries_path))\n",
    "\n",
    "# Model\n",
    "print(\"CROSS_ENCODER_MODEL_ID:\", globals().get(\"CROSS_ENCODER_MODEL_ID\", None),\n",
    "      \"| exists =\", _exists(globals().get(\"CROSS_ENCODER_MODEL_ID\", None)))\n",
    "\n",
    "# -----------------------------\n",
    "# Offline artifacts (required for inference, but may be restored)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Offline artifacts ---\")\n",
    "print(\"OFFLINE_BUNDLE_PKL   :\", globals().get(\"OFFLINE_BUNDLE_PKL\", None),\n",
    "      \"| exists =\", _exists(globals().get(\"OFFLINE_BUNDLE_PKL\", None)))\n",
    "print(\"ONTOLOGY_INTERNAL_CSV:\", globals().get(\"ONTOLOGY_INTERNAL_CSV\", None),\n",
    "      \"| exists =\", _exists(globals().get(\"ONTOLOGY_INTERNAL_CSV\", None)))\n",
    "\n",
    "# -----------------------------\n",
    "# Inference artifacts (optional)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Inference artifacts ---\")\n",
    "print(\"INFER_INPUT_CSV:\", globals().get(\"INFER_INPUT_CSV\", None),\n",
    "      \"| exists =\", _exists(globals().get(\"INFER_INPUT_CSV\", None)))\n",
    "print(\"INFER_OUT_CSV  :\", globals().get(\"INFER_OUT_CSV\", None),\n",
    "      \"| exists =\", _exists(globals().get(\"INFER_OUT_CSV\", None)))\n",
    "\n",
    "# -----------------------------\n",
    "# Export ZIPs (local design)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Exports ---\")\n",
    "exports_dir = Path(globals().get(\"OUT_DIR\", \".\")) / \"exports\"\n",
    "print(\"Exports dir:\", exports_dir, \"| exists =\", exports_dir.exists())\n",
    "if exports_dir.exists():\n",
    "    zips = sorted([p.name for p in exports_dir.glob(\"*.zip\")])\n",
    "    print(\"ZIPs:\", zips if zips else \"(none yet)\")\n",
    "\n",
    "print(\"\\nTip:\")\n",
    "print(\" - If something is missing, check the stage logs under:\")\n",
    "print(\"   \", Path(globals().get(\"OUT_DIR\", \".\")) / \"training\" / \"training.log\")\n",
    "print(\"   \", Path(globals().get(\"OUT_DIR\", \".\")) / \"offline\" / \"offline_bundle.log\")\n",
    "print(\"   \", Path(globals().get(\"OUT_DIR\", \".\")) / \"inference\" / \"inference.log\")\n",
    "print(\"=== END SUMMARY ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1b690",
   "metadata": {},
   "source": [
    "### C.A) Preview `predictions.csv` (optional)\n",
    "\n",
    "This is a convenience cell to quickly inspect a few rows of the inference output locally.\n",
    "It is safe to run even if inference was skipped: it will just print a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13708f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PREVIEW PREDICTIONS (optional) — stage-aware\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None\n",
    "\n",
    "pred_path = Path(globals().get(\"INFER_OUT_CSV\", \"predictions.csv\"))\n",
    "\n",
    "if not pred_path.exists():\n",
    "    print(\"Predictions not found:\", pred_path)\n",
    "elif pd is None:\n",
    "    print(\"pandas is not installed. Install with: pip install pandas\")\n",
    "else:\n",
    "    df = pd.read_csv(pred_path)\n",
    "    print(\"Predictions path :\", pred_path)\n",
    "    print(\"Predictions shape:\", df.shape)\n",
    "    display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c7f16",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12672f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d65832",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a6f23",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "This cells evaluate the inference output (`predictions.csv`) against the ground-truth gold file produced by the dataset builder (`training_dataset.test.gold.csv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eabd68",
   "metadata": {},
   "source": [
    "## Evaluation setup and path resolution\n",
    "\n",
    "This cell defines the configuration and resolves all file paths required for evaluation.\n",
    "\n",
    "Specifically, it:\n",
    "- sets the evaluation hyperparameters (e.g. `K`, `SAVE_MERGED`)\n",
    "- validates the existence of the inference output file (`predictions.csv`)\n",
    "- resolves the default gold file produced by the dataset construction step\n",
    "- prepares output locations for evaluation artifacts (e.g. `merged_eval.csv`)\n",
    "- optionally allows overriding the gold file path for custom evaluation scenarios\n",
    "\n",
    "This separation ensures that:\n",
    "- all path-related logic is explicit and easy to audit\n",
    "- the evaluation logic itself remains independent from filesystem concerns\n",
    "- alternative gold files can be tested without modifying the evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f184095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================\n",
    "# EVALUATION CONFIG\n",
    "# ============================================\n",
    "K = int(CROSS_TOP_K) if \"CROSS_TOP_K\" in globals() else 10  # default: use same K as cross-encoder keep-top-k\n",
    "SAVE_MERGED = True\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# INPUT PATHS (derived from your notebook config)\n",
    "# ============================================\n",
    "pred_path = Path(INFER_OUT_CSV)\n",
    "if not pred_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"predictions file not found:\\n - {pred_path}\\n\\n\"\n",
    "        \"Run inference first or set INFER_OUT_CSV correctly.\"\n",
    "    )\n",
    "\n",
    "gold_path = Path(str(Path(OUT_DATASET_CSV).with_suffix(\".test.gold.csv\")))\n",
    "if not gold_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"gold file not found:\\n - {gold_path}\\n\\n\"\n",
    "        \"Expected it to be produced by the dataset builder/split step.\"\n",
    "    )\n",
    "\n",
    "out_dir = pred_path.parent\n",
    "merged_out_path = out_dir / \"merged_eval.csv\"\n",
    "\n",
    "# ============================================\n",
    "# OPTIONAL GOLD OVERRIDE\n",
    "# ============================================\n",
    "# If provided, this path is used instead of the gold file\n",
    "# produced by the dataset construction step.\n",
    "GOLD_PATH_OVERRIDE = None  # e.g. \"my_eval/custom_gold.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a60255",
   "metadata": {},
   "source": [
    "## Evaluation logic and metrics computation\n",
    "\n",
    "This cell performs the actual evaluation of the inference results against the gold ground truth.\n",
    "\n",
    "The evaluation workflow is the following:\n",
    "- load predictions and gold dataframes\n",
    "- ensure compatibility by treating the gold file as all-positive if no `match` column is present\n",
    "- join predictions and gold preferably on `source_iri` (with `row_id` as a fallback)\n",
    "- compute basic statistics such as coverage and retrieval-source distribution\n",
    "- compute ranking metrics **on positive examples only**, including:\n",
    "  - Precision@1\n",
    "  - Hits@K\n",
    "  - MRR@K\n",
    "- correctly handle cases where a single query has multiple valid gold IRIs\n",
    "- optionally report metrics broken down by `retrieval_source`\n",
    "- optionally save a merged predictions–gold CSV for debugging and inspection\n",
    "\n",
    "The logic is designed to be robust to different gold formats while preserving\n",
    "the original evaluation semantics of the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# HELPERS (kept minimal and self-contained)\n",
    "# ============================================\n",
    "def _as_int01(x) -> Optional[int]:\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    try:\n",
    "        v = float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "    return 1 if v >= 0.5 else 0\n",
    "\n",
    "\n",
    "def _parse_gold(v: Any) -> List[str]:\n",
    "    \"\"\"\n",
    "    gold_target_iris may be:\n",
    "      - a single IRI string\n",
    "      - a stringified Python list, e.g. \"['iri1']\" or \"['iri1', 'iri2']\"\n",
    "    \"\"\"\n",
    "    if isinstance(v, list):\n",
    "        return [str(x) for x in v if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
    "    if pd.isna(v):\n",
    "        return []\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                vv = ast.literal_eval(s)\n",
    "                if isinstance(vv, list):\n",
    "                    return [str(x) for x in vv if x is not None]\n",
    "            except Exception:\n",
    "                pass\n",
    "        return [s]\n",
    "    return [str(v)]\n",
    "\n",
    "\n",
    "def compute_basic_stats(df_pred: pd.DataFrame) -> Dict[str, Any]:\n",
    "    n = len(df_pred)\n",
    "    out: Dict[str, Any] = {\"n\": int(n)}\n",
    "    if n == 0:\n",
    "        out[\"coverage\"] = float(\"nan\")\n",
    "        return out\n",
    "\n",
    "    out[\"coverage\"] = float(df_pred[\"predicted_iri\"].notna().mean()) if \"predicted_iri\" in df_pred.columns else 0.0\n",
    "\n",
    "    if \"retrieval_source\" in df_pred.columns:\n",
    "        vc = df_pred[\"retrieval_source\"].fillna(\"none\").astype(str).value_counts(normalize=True)\n",
    "        out[\"retrieval_source_dist\"] = {k: float(v) for k, v in vc.items()}\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_ranking_metrics_on_positives(\n",
    "    merged: pd.DataFrame,\n",
    "    *,\n",
    "    gold_col: str = \"gold_target_iris\",\n",
    "    match_col: str = \"match\",\n",
    "    k: int = 10,\n",
    ") -> Dict[str, float]:\n",
    "    if gold_col not in merged.columns:\n",
    "        raise ValueError(f\"Missing gold column: {gold_col}\")\n",
    "    if match_col not in merged.columns:\n",
    "        raise ValueError(f\"Missing match column: {match_col}\")\n",
    "    if \"predicted_iri\" not in merged.columns:\n",
    "        raise ValueError(\"Predictions missing 'predicted_iri'.\")\n",
    "\n",
    "    y = merged[match_col].apply(_as_int01)\n",
    "    df_pos = merged.loc[y == 1].copy()\n",
    "    n_pos = len(df_pos)\n",
    "    if n_pos == 0:\n",
    "        return {\n",
    "            \"n_pos\": 0.0,\n",
    "            \"precision_at_1_pos\": float(\"nan\"),\n",
    "            \"hits_at_k_pos\": float(\"nan\"),\n",
    "            \"mrr_at_k_pos\": float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    use_k = max(int(k), 1)\n",
    "\n",
    "    ranked_lists: List[List[str]] = []\n",
    "    gold_lists: List[List[str]] = []\n",
    "\n",
    "    for _, r in df_pos.iterrows():\n",
    "        ranks: List[str] = []\n",
    "        ranks.append(\"\" if pd.isna(r[\"predicted_iri\"]) else str(r[\"predicted_iri\"]))\n",
    "        for kk in range(2, use_k + 1):\n",
    "            c = f\"top{kk}_iri\"\n",
    "            if c in df_pos.columns:\n",
    "                ranks.append(\"\" if pd.isna(r[c]) else str(r[c]))\n",
    "        ranks = ranks[:use_k]\n",
    "        ranked_lists.append(ranks)\n",
    "\n",
    "        gold_lists.append(_parse_gold(r[gold_col]))\n",
    "\n",
    "    pred1 = df_pos[\"predicted_iri\"].astype(str).tolist()\n",
    "\n",
    "    # Precision@1 on positives: correct if predicted_iri matches ANY gold IRI.\n",
    "    correct1 = 0\n",
    "    for g_list, p in zip(gold_lists, pred1):\n",
    "        if p in set(g_list):\n",
    "            correct1 += 1\n",
    "    p_at_1 = correct1 / n_pos\n",
    "\n",
    "    # Hits@K and MRR@K: hit if ANY gold appears; MRR uses best (lowest) rank among gold IRIs.\n",
    "    hits = 0\n",
    "    rr_sum = 0.0\n",
    "    for g_list, ranks in zip(gold_lists, ranked_lists):\n",
    "        gset = set(g_list)\n",
    "        best_rank = None\n",
    "        for idx, iri in enumerate(ranks, start=1):\n",
    "            if iri in gset:\n",
    "                best_rank = idx\n",
    "                break\n",
    "        if best_rank is not None:\n",
    "            hits += 1\n",
    "            rr_sum += 1.0 / best_rank\n",
    "\n",
    "    return {\n",
    "        \"n_pos\": float(n_pos),\n",
    "        \"precision_at_1_pos\": float(p_at_1),\n",
    "        \"hits_at_k_pos\": float(hits / n_pos),\n",
    "        \"mrr_at_k_pos\": float(rr_sum / n_pos),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# LOAD FILES\n",
    "# ============================================\n",
    "df_pred = pd.read_csv(pred_path)\n",
    "df_gold = pd.read_csv(gold_path)\n",
    "\n",
    "# If the gold file has no match column, treat it as all positives.\n",
    "if \"match\" not in df_gold.columns:\n",
    "    df_gold[\"match\"] = 1\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# JOIN (prefer source_iri, fallback to row_id)\n",
    "# ============================================\n",
    "if (\"source_iri\" in df_pred.columns) and (\"source_iri\" in df_gold.columns):\n",
    "    merged = df_pred.merge(df_gold, on=\"source_iri\", how=\"left\", suffixes=(\"_pred\", \"_gt\"))\n",
    "    join_plan = \"source_iri\"\n",
    "elif \"row_id\" in df_pred.columns:\n",
    "    df_gold_idx = df_gold.reset_index(drop=False).rename(columns={\"index\": \"__gt_index\"})\n",
    "    merged = df_pred.merge(\n",
    "        df_gold_idx,\n",
    "        left_on=\"row_id\",\n",
    "        right_on=\"__gt_index\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_pred\", \"_gt\"),\n",
    "    ).drop(columns=[\"__gt_index\"])\n",
    "    join_plan = \"row_id\"\n",
    "else:\n",
    "    raise ValueError(\"Cannot join predictions and gold: need either source_iri in both files or row_id in predictions.\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# METRICS + REPORT\n",
    "# ============================================\n",
    "stats = compute_basic_stats(df_pred)\n",
    "gold_present = merged[\"gold_target_iris\"].notna().mean() if \"gold_target_iris\" in merged.columns else 0.0\n",
    "\n",
    "metrics = compute_ranking_metrics_on_positives(\n",
    "    merged,\n",
    "    gold_col=\"gold_target_iris\",\n",
    "    match_col=\"match\",\n",
    "    k=K,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Evaluation Report ===\")\n",
    "print(f\"Join method: {join_plan}\")\n",
    "print(f\"Pred rows: {stats['n']}\")\n",
    "print(f\"Coverage (predicted_iri != null): {stats.get('coverage', float('nan')):.4f}\")\n",
    "print(f\"GT attach rate (gold present after join): {gold_present:.4f}\")\n",
    "\n",
    "rs = stats.get(\"retrieval_source_dist\")\n",
    "if isinstance(rs, dict):\n",
    "    print(\"\\nRetrieval source distribution:\")\n",
    "    for k_, v_ in sorted(rs.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {k_:>8s}: {v_:.4f}\")\n",
    "\n",
    "print(\"\\nMetrics on POSITIVES only (match==1):\")\n",
    "print(f\"  n_pos:             {int(metrics['n_pos'])}\")\n",
    "print(f\"  Precision@1 (pos): {metrics['precision_at_1_pos']:.4f}\")\n",
    "print(f\"  Hits@{int(K)} (pos):     {metrics['hits_at_k_pos']:.4f}\")\n",
    "print(f\"  MRR@{int(K)} (pos):      {metrics['mrr_at_k_pos']:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# BREAKDOWN BY retrieval_source (if present)\n",
    "# ============================================\n",
    "if \"retrieval_source\" in merged.columns:\n",
    "    print(\"\\n=== Breakdown by Retrieval Source ===\")\n",
    "    for src in sorted(merged[\"retrieval_source\"].dropna().unique()):\n",
    "        subset = merged[merged[\"retrieval_source\"] == src].copy()\n",
    "        sub_metrics = compute_ranking_metrics_on_positives(\n",
    "            subset,\n",
    "            gold_col=\"gold_target_iris\",\n",
    "            match_col=\"match\",\n",
    "            k=K,\n",
    "        )\n",
    "        if sub_metrics[\"n_pos\"] > 0:\n",
    "            print(f\"\\nSource: {src}\")\n",
    "            print(f\"  n_pos:             {int(sub_metrics['n_pos'])}\")\n",
    "            print(f\"  Precision@1 (pos): {sub_metrics['precision_at_1_pos']:.4f}\")\n",
    "            print(f\"  Hits@{int(K)} (pos):     {sub_metrics['hits_at_k_pos']:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# SAVE MERGED CSV (optional but very useful for debugging)\n",
    "# ============================================\n",
    "if SAVE_MERGED:\n",
    "    merged.to_csv(merged_out_path, index=False)\n",
    "    print(f\"\\nSaved merged CSV to: {merged_out_path}\")\n",
    "\n",
    "print(\"\\n[DONE]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e9a55",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OAvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
